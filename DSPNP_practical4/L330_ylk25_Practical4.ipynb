{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Session 4: Getting Started with Deep Learning Models in TensorFlow\n",
    "\n",
    "*This notebook is based on past years' notebooks by Marek Rei and Guy Emerson*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical will cover a few different network architectures and we will look at different components that are often used in neural networks in practice. It will also allow you to learn more about [`TensorFlow`](https://www.tensorflow.org), a popular open-source machine learning and deep learning library. I'd also recommend checking the `TensorFlow` documentation to learn more about the rich functionality of this toolkit.\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "In this practical you will learn about:\n",
    "- The basics of running `TensorFlow` \n",
    "- How to implement a feedforward neural network in Python\n",
    "- How to visualise your network architecture using `TensorBoard` and track changes \n",
    "- How to apply deep learning to both classification and regression tasks.\n",
    "\n",
    "**Additional references**: Aurelien Geron, *Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow*.\n",
    "\n",
    "Before we start, let's import the usual libraries as we did in previous practicals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import numpy as np \n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import `TensorFlow` into our notebook. Note: `TensorFlow` v2 was released last year, and it mostly relies on `Keras` interpretative module fit on top of it. As a result, it is much more interpretable and user-friendly than v1, however if you want to better understand the inner workings of `TensorFlow` you are welcome to check the accompanying notebook [`DSPNP_practical4-TFv1.ipynb`](./DSPNP_practical4-TFv1.ipynb): even if you are using `TensorFlow2`, you can still switch to using v1 API, which is available as a submodule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.compat.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimal TensorFlow Example\n",
    "\n",
    "In this example, we create a simple network that takes an input vector, multiplies it by a weight matrix, adds a weight vector, and returns the result.\n",
    "\n",
    "`tf.Variable` defines model parameters, which can be trained (as we will see shortly). Here, we initialise the matrix variable as a 3x3 matrix, with every entry as 1 (`tf.ones`). Meanwhile, we initialise the 3x1 vector variable with every entry as 0 (`tf.zeros`). `tf.linalg.matvec` multiplies a matrix and a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([12. 12. 12.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "weight_matrix = tf.Variable(tf.ones(shape=(3,3)))\n",
    "weight_vector = tf.Variable(tf.zeros(shape=(3,)))\n",
    "\n",
    "def affine_transformation(input_vector):\n",
    "    return tf.linalg.matvec(weight_matrix, input_vector) + weight_vector\n",
    "\n",
    "result = affine_transformation([2.,3.,7.])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following [reset function](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session) is often useful. It is necessary to reset the `TensorFlow` network from time to time: as we have many different small networks in one notebook and we don't want them interfering with each other, as a pre-emptive measure we will occasionally reset the computation graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.backend.clear_session()>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Parameters\n",
    "\n",
    "This example shows how to optimise the parameters in your model.\n",
    "\n",
    "We first define a network that takes an input vector, multiplies it with a matrix (as defined above), and sums the elements of the resulting vector (using `tf.math.reduce_sum`). We then define a loss function as the square error. Given a specific input and output, we can calculate the loss of applying the network to the input.\n",
    "\n",
    "Next, we define an optimiser – here, we are using *stochastic gradient descent* (*SGD*) with the learning rate $0.001$. We then use this optimiser to train this network for $10$ epochs, over this single training point. This optimises the output towards the target value $20$. Printing out the results, we can see that the output gradually moves towards the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-24.48, shape=(), dtype=float32)\n",
      "tf.Tensor(143.6544, shape=(), dtype=float32)\n",
      "tf.Tensor(-323.75922, shape=(), dtype=float32)\n",
      "tf.Tensor(975.6506, shape=(), dtype=float32)\n",
      "tf.Tensor(-2636.7085, shape=(), dtype=float32)\n",
      "tf.Tensor(7405.6504, shape=(), dtype=float32)\n",
      "tf.Tensor(-20512.11, shape=(), dtype=float32)\n",
      "tf.Tensor(57099.266, shape=(), dtype=float32)\n",
      "tf.Tensor(-158660.36, shape=(), dtype=float32)\n",
      "tf.Tensor(441151.38, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "alpha = 1e-2\n",
    "number_of_epochs = 10\n",
    "\n",
    "tf.keras.backend.clear_session\n",
    "\n",
    "weight_matrix = tf.Variable(tf.ones(shape=(3,3)))\n",
    "weight_vector = tf.Variable(tf.zeros(shape=(3,)))\n",
    "\n",
    "def network(input_vector):\n",
    "    return tf.math.reduce_sum(affine_transformation(input_vector))\n",
    "\n",
    "def loss_fn(predicted, gold):\n",
    "    return tf.square(predicted - gold)\n",
    "\n",
    "input = [2.,3.,7.]\n",
    "gold_output = 20\n",
    "\n",
    "def loss():\n",
    "    return loss_fn(network(input), gold_output)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=alpha)\n",
    "\n",
    "for epoch in range(number_of_epochs):\n",
    "    opt.minimize(loss, var_list=[weight_matrix, weight_vector])\n",
    "    print(network(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional**: Try changing the learning rate and the number of epochs. What results are you getting?\n",
    "\n",
    "**Answer**: \n",
    "- Learning rate too small: loss is decreasing, but didn't reach the optium loss\n",
    "- Learning rate too big: unstable result, loss get bigger and bigger\n",
    "- Num of epochs increase: loss stablised\n",
    "- Num of epochs decrease: loss didn't stablise yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Layers\n",
    "\n",
    "For most cases, we don't actually need to create the trainable variables manually. Instead, the feedfoward layer is available as a pre-defined module.\n",
    "\n",
    "We can define a network as a sequence of operations, using [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). The first operation here is a dense feedforward layer (`tf.keras.layers.Dense`), which acts like the `affine_transfomation` function we defined earlier. The second operation sums the elements of the vector – this isn't a standard operation, so we use `tf.keras.layers.Lambda` to allow a user-defined function.\n",
    "\n",
    "By default, the parameters in a layer (like [`tf.keras.layers.Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)) are initialised randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape=(3,)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.reduce_sum(x, axis=1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that such a model expects the input data to be given as a *minibatch* – this means that the input tensor should have an extra index, which ranges over datapoints. In our case, instead of passing a 3-dimensional input vector, we have to pass an Nx3 matrix, where N is the number of datapoints. Here, we can apply the model to a single datapoint (a 1x3 matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.0901487], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tf.constant([[2.,3.,7.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model defined in terms of layers, let's replace the manually created variables of the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10.527716], shape=(1,), dtype=float32)\n",
      "tf.Tensor([14.108238], shape=(1,), dtype=float32)\n",
      "tf.Tensor([16.335325], shape=(1,), dtype=float32)\n",
      "tf.Tensor([17.720572], shape=(1,), dtype=float32)\n",
      "tf.Tensor([18.582195], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.118126], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.451473], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.65882], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.787783], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.868002], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape=(3,)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.reduce_sum(x, axis=1))\n",
    "])\n",
    "\n",
    "def loss_fn(predicted, gold):\n",
    "    return tf.square(predicted - gold)\n",
    "\n",
    "input = tf.constant([[2.,3.,7.]])\n",
    "gold_output = 20\n",
    "\n",
    "def loss():\n",
    "    return loss_fn(model(input), gold_output)\n",
    "\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    opt.minimize(loss, var_list=model.trainable_variables)\n",
    "    print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, for standard optimizers and loss functions, the `TensorFlow` API makes it even easier for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.381605, shape=(), dtype=float32)\n",
      "tf.Tensor(15.883356, shape=(), dtype=float32)\n",
      "tf.Tensor(17.43945, shape=(), dtype=float32)\n",
      "tf.Tensor(18.407335, shape=(), dtype=float32)\n",
      "tf.Tensor(19.009363, shape=(), dtype=float32)\n",
      "tf.Tensor(19.383823, shape=(), dtype=float32)\n",
      "tf.Tensor(19.61674, shape=(), dtype=float32)\n",
      "tf.Tensor(19.761612, shape=(), dtype=float32)\n",
      "tf.Tensor(19.851723, shape=(), dtype=float32)\n",
      "tf.Tensor(19.907772, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, input_shape=(3,)),\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.reduce_sum(x))\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3), # alternatively, optimizer=`sgd`\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "input = tf.constant([[2.,3.,7.]])\n",
    "gold_output = tf.constant([[20.]])\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train_on_batch(input, gold_output)\n",
    "    print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "As you saw in the previous lectures, activation functions are what gives neural networks their power to model non-linear patterns in the data. After applying an affine transformation, we then apply a non-linear activation function to each element. There are a number of different activation functions to choose from.\n",
    "\n",
    "The [sigmoid function](https://en.wikipedia.org/wiki/Logistic_function), also known as the logistic function, is the most classic non-linear activation. It transforms the value to a range between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.keras.layers.Dense(100, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In modern networks, the [tanh function](https://en.wikipedia.org/wiki/Hyperbolic_function) is used more often. It has more flexibility, as it transforms the input value to a range between -1 and 1, and can therefore output negative values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.keras.layers.Dense(100, activation='tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular one is the [Rectified Linear Unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) function, or the ReLU. This function acts as a linear function above zero, but restricts everything below zero to 0. By doing this it also introduces non-linearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = tf.keras.layers.Dense(100, activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial linear property of the ReLU can help it converge faster on some tasks, although in practice tanh may be a more robust option.\n",
    "\n",
    "Finally, for classification tasks [softmax](https://en.wikipedia.org/wiki/Softmax_function) is an important activation function. Unlike the activation functions mentioned above, it isn't applied to each element separately. It converts a vector of scores into a probability distribution: after applying the softmax, all values are between 0 and 1, and together they sum to 1. Higher scores are assigned to higher probabilities, via the formula:\n",
    "\n",
    "<center>\n",
    "$P(i) \\propto \\exp(x_i)$\n",
    "</center>\n",
    "\n",
    "Or, more explicitly:\n",
    "\n",
    "<center>\n",
    "$P(i) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
    "</center>\n",
    "\n",
    "Notice how the value of the denominator depends on all other values.\n",
    "\n",
    "The softmax is often used in the output layer of a network performing classification, in order to predict a probability distribution over all the possible classes. For example, the following model takes a 20-dimensional input, maps it to a 50-dimensional hidden layer, then maps it to a distribution over 10 output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, input_shape=(20,), activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations and Useful Functions\n",
    "\n",
    "`TensorFlow` has corresponding versions of all the main operations you might want to use. This means you can add them into your computation graph and into your neural network. The most common operations are available in `tf`, and further operations are available in `tf.math`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.exp(x, name=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.abs # absolute value\n",
    "tf.negative # computes the negative value\n",
    "tf.sign # returns 1, 0 or -1 depending on the sign of the input\n",
    "tf.math.reciprocal # reciprocal 1/x\n",
    "tf.square # return input squared\n",
    "tf.round # return rounded value\n",
    "tf.sqrt # square root\n",
    "tf.math.rsqrt # reciprocal of square root\n",
    "tf.pow # power\n",
    "tf.exp # exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations can be applied to scalar values, but also to vectors, matrices and higher-order tensors. In the latter case, they will be applied element-wise. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-3.2  2.7], shape=(2,), dtype=float32)\n",
      "tf.Tensor([2.25      4.4099994], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.negative([3.2,-2.7]))\n",
    "print(tf.square([1.5,-2.1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful operations are performed over a whole vector/matrix tensor and return a single value (e.g., you saw `tf.reduce_sum` earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.math_ops.argmin_v2(input, axis=None, output_type=tf.int64, name=None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum # Add elements together\n",
    "tf.reduce_mean # Average over elements\n",
    "tf.reduce_min # Minimum value\n",
    "tf.reduce_max # Maximum value\n",
    "tf.argmax # Index of the largest value\n",
    "tf.argmin # Index of the smallest value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Learning Rates\n",
    "\n",
    "Above, we used stochastic gradient descent (SGD) to train our model. This uses a fixed learning rate to update the parameters. Several optimisation algorithms are based on SGD, but adaptively adjust the learning rate (usually for each parameter separately).\n",
    "\n",
    "Different adaptive learning rate strategies are also implemented in `TensorFlow` as functions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.optimizer_v2.rmsprop.RMSprop"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.optimizers.SGD\n",
    "tf.keras.optimizers.Adadelta\n",
    "tf.keras.optimizers.Adam\n",
    "tf.keras.optimizers.RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in the differences between these strategies, [this blog post](http://ruder.io/optimizing-gradient-descent/) provides more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an XOR Function\n",
    "\n",
    "[XOR](https://en.wikipedia.org/wiki/XOR_gate) is the function that takes two binary values and returns 1 only if one of them is 1 and the other 0, while returning 0 if both of them have the same value. It can be a difficult function to learn and cannot be modelled with a linear model. But let's try anyway.\n",
    "\n",
    "Our dataset consists of all the possible different states that XOR can take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_input = tf.constant([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
    "xor_output = tf.constant([0.0, 1.0, 1.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we construct a linear network and optimize it on this dataset, printing out the predictions at each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epochs: [ 0.3259965  -0.10851547  1.0372578   0.6027459 ]\n",
      "after 20 epochs: [0.3775949  0.13760306 0.82361984 0.583628  ]\n",
      "after 30 epochs: [0.41110516 0.2806741  0.6914177  0.56098664]\n",
      "after 40 epochs: [0.43537933 0.36689535 0.61282265 0.5443387 ]\n",
      "after 50 epochs: [0.4530237  0.41900516 0.5662509  0.53223234]\n",
      "after 60 epochs: [0.46585035 0.45056018 0.5387217  0.5234315 ]\n",
      "after 70 epochs: [0.47517473 0.46971142 0.52249694 0.51703364]\n",
      "after 80 epochs: [0.48195314 0.4813656  0.51297027 0.5123827 ]\n",
      "after 90 epochs: [0.48688072 0.48847976 0.5074026  0.5090017 ]\n",
      "after 100 epochs: [0.49046287 0.4928384  0.5041683  0.5065438 ]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "linear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(2,))\n",
    "])\n",
    "\n",
    "linear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "                     loss='mean_squared_error')\n",
    "\n",
    "for epoch in range(100):\n",
    "    linear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), linear_model(xor_input).numpy().reshape((4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it's not doing very well. Ideally, the predictions should be [0, 1, 1, 0], but in this case they are hovering around 0.5 for every input case.\n",
    "\n",
    "In order to improve this architecture, let's add some non-linear layers into our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epochs: [0.49417958 0.5899419  0.381775   0.49363616]\n",
      "after 20 epochs: [0.4616477  0.59616727 0.43106332 0.50130224]\n",
      "after 30 epochs: [0.424308  0.6186376 0.4576356 0.5110656]\n",
      "after 40 epochs: [0.37664062 0.6509645  0.47221428 0.5139635 ]\n",
      "after 50 epochs: [0.3269036  0.68852186 0.48768112 0.50682783]\n",
      "after 60 epochs: [0.28414962 0.7229547  0.5129224  0.48719934]\n",
      "after 70 epochs: [0.2523722  0.74790955 0.5552972  0.45223424]\n",
      "after 80 epochs: [0.2286303  0.76433665 0.61369026 0.40098327]\n",
      "after 90 epochs: [0.206866   0.77994895 0.67464316 0.34294444]\n",
      "after 100 epochs: [0.1846543  0.79843694 0.7262142  0.29116237]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(5, input_shape=(2,), activation='tanh'), # note that these settings can be changed\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='mean_squared_error')\n",
    "\n",
    "for epoch in range(100):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy().reshape((4,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much better. The values are much closer to [0, 1, 1, 0] than before, and they will continue improving if we train for longer. (Remember that the model is initialised randomly – if you run it a few times, you will see that the results vary with each run. Check the [documentation](https://www.tensorflow.org/tutorials/keras/save_and_load) on how you can save and restore a particular model).\n",
    "\n",
    "We also had to increase the learning rate for this network. It would still be learning with a smaller learning rate, but it would be converging very slowly. As we discussed in the lectures, learning rate is a hyperparameter that can vary quite a bit depending on the network architecture and dataset.\n",
    "\n",
    "**Optional**: Try changing various settings in the current network, e.g. *width* (number of neurons per layer), *depth* (number of layers), *activation functions* applied to each layer, and number of *epochs*. What changes do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Classification\n",
    "\n",
    "We can also do classification with `TensorFlow`. For this, we often use the softmax activation function described above, which predicts the probability for each of the possible classes.\n",
    "\n",
    "We also have to change the loss function, as squared error is not suitable for classification. A suitable loss function is [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy). Since the correct output has probability 1 for the correct class, and probability 0 for the rest, minimising cross entropy is the same as minimising the negative log probability of the correct class for each datapoint. In other words, by minimising cross entropy, we are trying to find the maximum likelihood model, which assigns high values for the correct label.\n",
    "\n",
    "We can change the XOR example above to perform classification instead. In this case, we are constructing a binary classifier – choosing between the classes of 0 and 1. The output here prints the predicted probabilities of the two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epochs:\n",
      "[[0.64263344 0.35736653]\n",
      " [0.5267876  0.4732124 ]\n",
      " [0.48214647 0.5178535 ]\n",
      " [0.841253   0.15874702]]\n",
      "after 20 epochs:\n",
      "[[0.7458722  0.25412783]\n",
      " [0.17568107 0.824319  ]\n",
      " [0.15599185 0.84400815]\n",
      " [0.9061508  0.09384919]]\n",
      "after 30 epochs:\n",
      "[[0.8607714  0.13922861]\n",
      " [0.06611789 0.9338821 ]\n",
      " [0.03200986 0.9679901 ]\n",
      " [0.94203967 0.0579603 ]]\n",
      "after 40 epochs:\n",
      "[[0.91949904 0.08050098]\n",
      " [0.04171929 0.9582807 ]\n",
      " [0.03175868 0.9682413 ]\n",
      " [0.98098123 0.01901881]]\n",
      "after 50 epochs:\n",
      "[[0.94576424 0.05423581]\n",
      " [0.02591982 0.97408015]\n",
      " [0.01834871 0.9816513 ]\n",
      " [0.9876409  0.01235908]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "for epoch in range(50):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert these probabilities into class predictions and also report some of the more familiar [evaluation metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics), e.g. *accuracy*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After 10 epochs: 1 1 1 0\n",
      "1/1 - 0s - loss: 0.6879 - accuracy: 0.7500\n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "After 20 epochs: 1 1 1 0\n",
      "1/1 - 0s - loss: 0.6482 - accuracy: 0.7500\n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "After 30 epochs: 1 1 1 0\n",
      "1/1 - 0s - loss: 0.5772 - accuracy: 0.7500\n",
      "\n",
      "Accuracy: 0.75\n",
      "\n",
      "After 40 epochs: 0 1 1 0\n",
      "1/1 - 0s - loss: 0.4982 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "After 50 epochs: 0 1 1 0\n",
      "1/1 - 0s - loss: 0.4325 - accuracy: 1.0000\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])  \n",
    "\n",
    "for epoch in range(50):\n",
    "    nonlinear_model.train_on_batch(xor_input, xor_output)\n",
    "    predictions = nonlinear_model.predict(xor_input)\n",
    "    result = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('\\nAfter {} epochs:'.format(epoch+1), \" \".join([str(x) for x in result.numpy()]))\n",
    "        test_loss, test_acc = nonlinear_model.evaluate(xor_input, xor_output, verbose=2)\n",
    "        print('\\nAccuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see in this printout that the model starts off with incorrect predictions, but fairly soon learns to return the correct sequence of [0, 1, 1, 0].\n",
    "\n",
    "Finally, here is how you can print out the confusion matrix. Since we are looking into a simple case here and the predictions from above are quite accurate, there is not much to be learned from the confusion matrix at this point (but note that this functionality may come in handy later in your practical):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [0 2]]\n"
     ]
    }
   ],
   "source": [
    "conf_mx = tf.math.confusion_matrix(xor_output, result.numpy()).numpy()\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minibatching\n",
    "\n",
    "For the XOR data, there are only 4 datapoints. However, with realistic datasets, it is inefficient to train on the whole dataset at once, because this will require a lot of computation in order to make a single update step. \n",
    "\n",
    "Instead, we can train on a batch of data at a time. For example, here is how you can take batches of 2 datapoints for the XOR data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epochs:\n",
      "[[0.57497793 0.4250221 ]\n",
      " [0.07100596 0.92899406]\n",
      " [0.46021643 0.53978354]\n",
      " [0.5707003  0.42929977]]\n",
      "after 20 epochs:\n",
      "[[0.8762206  0.12377941]\n",
      " [0.0398332  0.9601668 ]\n",
      " [0.02894458 0.97105545]\n",
      " [0.87674415 0.12325591]]\n",
      "after 30 epochs:\n",
      "[[0.95234853 0.04765148]\n",
      " [0.01536203 0.9846379 ]\n",
      " [0.02257047 0.9774295 ]\n",
      " [0.952568   0.04743207]]\n",
      "after 40 epochs:\n",
      "[[0.97074944 0.02925051]\n",
      " [0.00868577 0.99131423]\n",
      " [0.00800478 0.9919952 ]\n",
      " [0.97084695 0.02915299]]\n",
      "after 50 epochs:\n",
      "[[0.9792398  0.02076015]\n",
      " [0.00702822 0.99297184]\n",
      " [0.00551754 0.9944825 ]\n",
      " [0.977271   0.02272902]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "for epoch in range(50):\n",
    "    for i in range(0,len(xor_input),BATCH_SIZE):\n",
    "        input_batch = xor_input[i:i+BATCH_SIZE]\n",
    "        output_batch = xor_output[i:i+BATCH_SIZE]\n",
    "        nonlinear_model.train_on_batch(input_batch, output_batch)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(xor_input).numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this kind of functionality is built into `TensorFlow`. The following code trains the model with the given batch size and number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.8612\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0292\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6930\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6876\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6540\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.9193\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1632\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6969\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6819\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.6597\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6688\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6245\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6424\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.5972\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5516\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.5939\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.6389\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.4616\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5429\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.9727\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3054\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.2155\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.1566\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1349\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1211\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.1007\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0846\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0696\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0595\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0608\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0479\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0444\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0393\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0375\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0360\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.033 - 0s 4ms/step - loss: 0.0324\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0324\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0302\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0268\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0263\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 0.0256\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0241\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0222\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.0207\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0195\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0193\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0172\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "final loss: 0.0158169437199831\n",
      "final predictions:\n",
      "[[0.9755515  0.02444853]\n",
      " [0.00721646 0.99278355]\n",
      " [0.00649917 0.99350077]\n",
      " [0.9755515  0.02444853]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(xor_input, xor_output, batch_size=2, epochs=50)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(xor_input, xor_output))\n",
    "print('final predictions:', nonlinear_model.predict(xor_input), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard\n",
    "\n",
    "So far, you have been exploring the results using simple print out messages. However, neural networks can grow very large and complicated, and you may wish to visualise and explore various components along the way. Visualisation in this case is not only a useful method for reporting and sharing your results, but also a good way to inspect your network and debug it. \n",
    "\n",
    "[`TensorBoard`](https://www.tensorflow.org/tensorboard) provides you with all the needed visualisation functionality and allows you to:\n",
    "\n",
    "- track and visualise metrics such as loss and accuracy;\n",
    "- visualise the model graph (ops and layers);\n",
    "- view histograms of weights, biases, or other tensors as they change over time;\n",
    "- project embeddings to a lower dimensional space;\n",
    "- display images, text, and audio data;\n",
    "- profile TensorFlow programs;\n",
    "\n",
    "among other things. Moreover, you can run it in your browser or embed it directly into your notebook as the code below shows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you will likely be introducing changes into your network and rerunning your code, it's important to be able to distinguish between these different runs to track the changes. Every time you run a new model, it will be stored in log files and added to your `TensorBoard`, so a good way to distinguish between various models is to add a time stamp to each of them. Let's add this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make sure you clean all the previous logs (e.g., if you've run this notebook before). You can clear any logs from previous runs by running `rm -rf ./logs/` from within your notebook folder in your terminal.\n",
    "\n",
    "Once this is done, let's train a network and store its details in the log files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6090WARNING:tensorflow:From /Users/elim/opt/anaconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.4315WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0520s). Check your callbacks.\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.4315 - val_loss: 0.8558\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.8663 - val_loss: 0.6972\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.8422 - val_loss: 0.6832\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.3184 - val_loss: 0.7904\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0726 - val_loss: 0.7080\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8119 - val_loss: 0.6934\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0381 - val_loss: 0.7181\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.8010 - val_loss: 0.6934\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7458 - val_loss: 0.6936\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7363 - val_loss: 0.6948\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7230 - val_loss: 0.6932\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7177 - val_loss: 0.6931\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.7128 - val_loss: 0.6930\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7086 - val_loss: 0.6930\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.7052 - val_loss: 0.6929\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0350 - val_loss: 0.7219\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7365 - val_loss: 0.6935\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7048 - val_loss: 0.6931\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.7027 - val_loss: 0.6932\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6995 - val_loss: 0.6931\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6990 - val_loss: 0.6932\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6971 - val_loss: 0.6931\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.6963 - val_loss: 0.6931\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6956 - val_loss: 0.6931\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.8014 - val_loss: 0.6938\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6973 - val_loss: 0.6933\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7720 - val_loss: 0.6936\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.6963 - val_loss: 0.6933\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0135 - val_loss: 0.7201\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7147 - val_loss: 0.6941\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6961 - val_loss: 0.6933\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 1.0038 - val_loss: 0.7188\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7126 - val_loss: 0.6941\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1.0108 - val_loss: 0.7229\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.9899 - val_loss: 0.7047\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 1.0303 - val_loss: 0.7309\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7212 - val_loss: 0.6947\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0121 - val_loss: 0.7236\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 1.0533 - val_loss: 0.7390\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7258 - val_loss: 0.6952\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6952 - val_loss: 0.6933\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0064 - val_loss: 0.7208\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0505 - val_loss: 0.7380\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.9928 - val_loss: 0.7019\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7004 - val_loss: 0.6934\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.0004 - val_loss: 0.7180\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7104 - val_loss: 0.6943\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9980 - val_loss: 0.7165\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 1.0453 - val_loss: 0.7363\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9924 - val_loss: 0.7022\n",
      "1/1 [==============================] - 0s 921us/step - loss: 0.7022\n",
      "final loss: 0.7021617889404297\n",
      "final predictions:\n",
      "[[0.56700754 0.43299246]\n",
      " [0.56698227 0.43301767]\n",
      " [0.56668735 0.4333126 ]\n",
      " [0.56666213 0.43333793]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='tanh'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "nonlinear_model.fit(xor_input, xor_output, \n",
    "                    batch_size=2, epochs=50, \n",
    "                    validation_data=(xor_input, xor_output),\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(xor_input, xor_output))\n",
    "print('final predictions:', nonlinear_model.predict(xor_input), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you can explore your model in `TensorBoard`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c0554b06c1f556d6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c0554b06c1f556d6\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can explore both the results (e.g., learning curves) under the `Scalars` tab and the network architecture itself under the `Graphs` tab. All visualisations are interactive – note that you can scroll in on the network components in the `Graph` visualisation and double-click on the \"+\" sign in the upper right corner of any component to track operations, weights, etc.\n",
    "\n",
    "A brief overview of the dashboards from [`TensorBoard` documentation](https://www.tensorflow.org/tensorboard/get_started):\n",
    "\n",
    "- The `Scalars` dashboard shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values.\n",
    "- The `Graphs` dashboard helps you visualise your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly.\n",
    "- The `Distributions` and `Histograms` dashboards show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way.\n",
    "\n",
    "There are additional `TensorBoard` plugins, which are automatically enabled when you log other types of data (note, it is not applicable to this notebook, as you are not working with any other types of data here). For example, the Keras `TensorBoard` callback lets you log images and embeddings as well. You can see what other plugins are available in `TensorBoard` by clicking on the \"inactive\" dropdown towards the top right.\n",
    "\n",
    "\n",
    "# Keeping track of the history\n",
    "\n",
    "There are other ways to get more information and description of your model, which are useful when you introduce more complexity to the model and would like to keep track of the changes. We'll summarise them in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(2,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, here is how you can return the information on the networks' layers and their types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fd710f03550>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fd710f08bb0>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlinear_model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is how you can get a concise summary of the network layers (note that the first dimension in the output shape column is specified as `None` – this is to denote that this dimension is variable as it depends on the batch size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 52\n",
      "Trainable params: 52\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nonlinear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also plot tje model summary like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(nonlinear_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are a number of ways to extract (and store) the information on individual layers, as well as on weights and biases in the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_22'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = nonlinear_model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlinear_model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11545169,  0.21634954],\n",
       "       [ 0.3835712 , -0.390561  ],\n",
       "       [ 0.57737106,  0.59620816],\n",
       "       [ 0.2510231 ,  0.09301978],\n",
       "       [-0.66466975, -0.6046152 ],\n",
       "       [-0.5076999 ,  0.4714052 ],\n",
       "       [-0.27718398,  0.2752211 ],\n",
       "       [ 0.03581184,  0.04638898],\n",
       "       [ 0.44142455, -0.46810365],\n",
       "       [-0.5944241 ,  0.15561002]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model and track the changes in the loss and accuracy on the training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                       metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.9597 - accuracy: 0.5000 - val_loss: 0.6446 - val_accuracy: 0.7500\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6660 - accuracy: 0.5000 - val_loss: 0.6183 - val_accuracy: 0.7500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6582 - accuracy: 0.5000 - val_loss: 0.6353 - val_accuracy: 0.7500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.9738 - accuracy: 0.2500 - val_loss: 0.5898 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6235 - accuracy: 0.7500 - val_loss: 0.5702 - val_accuracy: 0.7500\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8142 - accuracy: 0.5000 - val_loss: 0.6492 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8611 - accuracy: 0.5000 - val_loss: 0.7748 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7440 - accuracy: 0.5000 - val_loss: 0.6972 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6962 - accuracy: 0.5000 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6909 - accuracy: 0.5000 - val_loss: 0.6841 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6880 - accuracy: 0.2500 - val_loss: 0.6873 - val_accuracy: 0.7500\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9937 - accuracy: 0.5000 - val_loss: 0.7183 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0239 - accuracy: 0.5000 - val_loss: 0.7156 - val_accuracy: 0.5000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9889 - accuracy: 0.5000 - val_loss: 0.7060 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.7010 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6920 - val_accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6908 - accuracy: 0.5000 - val_loss: 0.6888 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0041 - accuracy: 0.2500 - val_loss: 0.7218 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.7112 - accuracy: 0.5000 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6943 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0012 - accuracy: 0.5000 - val_loss: 0.7186 - val_accuracy: 0.5000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.7092 - accuracy: 0.5000 - val_loss: 0.6948 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.6942 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0052 - accuracy: 0.0000e+00 - val_loss: 0.7206 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7105 - accuracy: 0.5000 - val_loss: 0.6950 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 1.0124 - accuracy: 0.0000e+00 - val_loss: 0.7239 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.7125 - accuracy: 0.5000 - val_loss: 0.6952 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0032 - accuracy: 0.5000 - val_loss: 0.7196 - val_accuracy: 0.5000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0488 - accuracy: 0.0000e+00 - val_loss: 0.7375 - val_accuracy: 0.5000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 1.0674 - accuracy: 0.0000e+00 - val_loss: 0.7437 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.9943 - accuracy: 0.5000 - val_loss: 0.7010 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.9913 - accuracy: 0.5000 - val_loss: 0.7115 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.9892 - accuracy: 0.5000 - val_loss: 0.7076 - val_accuracy: 0.5000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.0342 - accuracy: 0.0000e+00 - val_loss: 0.7324 - val_accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.7180 - accuracy: 0.5000 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 1.0145 - accuracy: 0.0000e+00 - val_loss: 0.7248 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.9901 - accuracy: 0.5000 - val_loss: 0.7043 - val_accuracy: 0.5000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.7001 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.0087 - accuracy: 0.0000e+00 - val_loss: 0.7223 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.7115 - accuracy: 0.5000 - val_loss: 0.6951 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 1.0012 - accuracy: 0.5000 - val_loss: 0.7185 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.9894 - accuracy: 0.5000 - val_loss: 0.7057 - val_accuracy: 0.5000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7010 - accuracy: 0.5000 - val_loss: 0.6940 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = nonlinear_model.fit(xor_input, xor_output, batch_size=2, epochs=50,\n",
    "                    validation_data=(xor_input, xor_output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 50, 'steps': 2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the changes across all epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case of regression\n",
    "\n",
    "Finally, you can address not only classification but also regression tasks with `TensorFlow`. Let's look at a short example here.\n",
    "\n",
    "In Practical 1 you have been using a custom version of the California housing dataset (refer to the Practical 1 to see what differences were introduced in the original data). The original version is [accessible via `sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html), and the code below shows how to access a dataset from `sklearn` (in fact, `sklearn` provides access to a number of useful ML datasets, so take a look at the [documentation](https://scikit-learn.org/stable/datasets/index.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let't split the dataset into training, validation, and test sets. Note that you can access the data from the dataset with `housing.data`, and the labels with `housing.target`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And scale the data using standardisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows to you how to implement a regression model using `TensorFlow`. It is quite similar to the code for classification with minor difference: the loss function that you use here is mean squared error, and the output is a single predicted value thus the dimensionality of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.6419 - val_loss: 0.8560\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7047 - val_loss: 0.6531\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6345 - val_loss: 0.6099\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5977 - val_loss: 0.5658\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5706 - val_loss: 0.5355\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5472 - val_loss: 0.5173\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5288 - val_loss: 0.5081\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5130 - val_loss: 0.4799\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.4690\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4875 - val_loss: 0.4656\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4482\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4479\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4296\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4233\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4176\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4123\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4071\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4037\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.3969\n",
      "162/162 [==============================] - 0s 875us/step - loss: 0.4212\n"
     ]
    }
   ],
   "source": [
    "reg_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "reg_model.compile(loss=\"mean_squared_error\", optimizer=tf.keras.optimizers.SGD(lr=1e-3))\n",
    "history = reg_model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = reg_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also explore model's predictions on some selected datapoints and compare them to the true values for these datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3885664],\n",
       "       [1.6792021],\n",
       "       [3.1022797]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = reg_model.predict(X_new)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Classification of House Locations\n",
    "\n",
    "In the first practical, you used the California House Prices Dataset in order to predict the prices of the houses based on various properties about the houses. In this assignment, we will experiment with `TensorFlow` and train a model to predict the \"ocean proximity\" of a house.\n",
    "\n",
    "First, let's read in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('housing/housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the ocean proximity column from the other features and convert the values to numerical IDs. Remember, the `ocean_proximity` column already contains discrete classes, so it is well-suited for the classification task. However, these are strings and in order to optimise the softmax function in `TensorFlow`, we need numerical IDs instead of strings. We can use the `pandas` map function to do the conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy().drop([\"ocean_proximity\"], axis=1)\n",
    "Y = data.copy()[\"ocean_proximity\"]\n",
    "Y = data.copy()[\"ocean_proximity\"].map({\"<1H OCEAN\":0, \"INLAND\":1, \"ISLAND\": 2, \"NEAR BAY\": 3, \"NEAR OCEAN\": 4}).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's split off some data for development and testing:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=42)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's preprocess the input features before giving them to the network. We need to fill in missing values with the imputer, and standardise the values to a similar range using the scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn import preprocessing\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "imputer.fit(X_train)\n",
    "\n",
    "X_train = imputer.transform(X_train)\n",
    "X_dev = imputer.transform(X_dev)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_dev = scaler.transform(X_dev)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that we can work with.\n",
    "\n",
    "Input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13209, 9)\n",
      "(3303, 9)\n",
      "(4128, 9)\n",
      "[[-0.69155432  1.10281811 -0.12449485 -0.44361185 -0.60289408 -0.48710064\n",
      "  -0.64120663  0.44340968 -0.25873131]\n",
      " [ 0.8544348  -0.72493883 -1.07770852  1.75575918  1.99734983  1.69902706\n",
      "   2.04218568  0.00321001 -0.28999612]\n",
      " [ 0.86440892 -0.88428174 -0.20392932 -0.15088981 -0.02963101 -0.13535041\n",
      "  -0.16516379 -0.52181236 -0.01729749]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the correstponding gold-standard labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13209,)\n",
      "(3303,)\n",
      "(4128,)\n",
      "[1 0 0 4 1 1 3 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the code examples above, construct a `TensorFlow` model, then train, tune and test it on this dataset. Experiment with different model settings and hyperparameters. Calculate and evaluate classification accuracy - the percentage of datapoints where the predicted class matches the gold-standard class.\n",
    "\n",
    "During the practical session, give examples of what you tried and what your findings were.\n",
    "\n",
    "Some suggestions and tips:\n",
    "\n",
    "- The XOR classification code can be a good place to start.\n",
    "- The output layer needs to have size 5, because the dataset has 5 possible classes.\n",
    "- Try testing on the development set as you are training, to make sure you don't overfit.\n",
    "- Evaluate on the dev set as much as you want, but evaluate on the test set only after you have chosen a good set of hyperparameters.\n",
    "- You could try different learning rates, hidden layer sizes, learning strategies, etc.\n",
    "- Adaptive learning rates can (and sometimes should) be used together with a regular hand-picked learning rate, and different adaptive learning rates can prefer very different regular learning rates.\n",
    "\n",
    "There are a number of additional (optional) steps that you can try: you can visualise your network architecture, changes in loss and metrics, print out and visualise confusion matrices, implement \"traditional\" machine learning algorithms (e.g., from Practicals 2 and 3) and compare the results, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------\n",
    "### Using the cross entropy to calculate loss\n",
    "\n",
    "By minimising cross entropy, we can find the maximum likelihood model, which assigns high values for the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 10 epochs:\n",
      "[[0.1044118  0.6079772  0.02064831 0.15254098 0.11442178]\n",
      " [0.48580405 0.2641912  0.07754324 0.0544505  0.11801098]\n",
      " [0.639202   0.16429128 0.02475809 0.03754044 0.13420819]\n",
      " ...\n",
      " [0.76535463 0.1035298  0.0171157  0.01840601 0.09559391]\n",
      " [0.54655004 0.26238582 0.02963757 0.02817043 0.13325617]\n",
      " [0.68106234 0.13868678 0.01332291 0.02669211 0.14023583]]\n",
      "after 20 epochs:\n",
      "[[0.10099241 0.71108824 0.00843383 0.10520472 0.07428078]\n",
      " [0.52666235 0.2694589  0.04899354 0.04045461 0.11443052]\n",
      " [0.67960787 0.14334583 0.00978613 0.0126493  0.15461084]\n",
      " ...\n",
      " [0.78144413 0.08806934 0.00484014 0.00459618 0.12105022]\n",
      " [0.44140443 0.39819625 0.01091644 0.00945851 0.14002436]\n",
      " [0.699505   0.12774205 0.00567849 0.00909451 0.15797992]]\n",
      "after 30 epochs:\n",
      "[[0.07494255 0.81107414 0.00500292 0.06077779 0.04820262]\n",
      " [0.47046652 0.37048608 0.01652545 0.01388537 0.12863657]\n",
      " [0.7077287  0.10422228 0.00505724 0.00634081 0.17665094]\n",
      " ...\n",
      " [0.79308933 0.05673219 0.00196891 0.00171399 0.14649563]\n",
      " [0.43840134 0.39679092 0.00552222 0.00449597 0.15478957]\n",
      " [0.7440673  0.07972326 0.00352965 0.00523348 0.16744636]]\n",
      "after 40 epochs:\n",
      "[[0.04426435 0.89793754 0.00248034 0.03146562 0.0238521 ]\n",
      " [0.47230908 0.36928582 0.0101309  0.00861678 0.13965738]\n",
      " [0.7157145  0.08219588 0.00340627 0.00428026 0.19440304]\n",
      " ...\n",
      " [0.78872955 0.03737943 0.00122284 0.00102972 0.17163841]\n",
      " [0.4471685  0.382615   0.00370102 0.00296767 0.16354781]\n",
      " [0.7581932  0.06359963 0.00239429 0.00353497 0.17227788]]\n",
      "after 50 epochs:\n",
      "[[2.91933883e-02 9.40078676e-01 1.30261749e-03 1.78007074e-02\n",
      "  1.16245905e-02]\n",
      " [4.91421729e-01 3.54560167e-01 7.79051008e-03 6.89902203e-03\n",
      "  1.39328524e-01]\n",
      " [7.18097031e-01 7.23071471e-02 2.45364406e-03 3.18303122e-03\n",
      "  2.03959122e-01]\n",
      " ...\n",
      " [7.82975972e-01 2.40070429e-02 8.66526098e-04 7.28308165e-04\n",
      "  1.91422179e-01]\n",
      " [4.70165581e-01 3.59496117e-01 2.63983943e-03 2.20909435e-03\n",
      "  1.65489286e-01]\n",
      " [7.72405267e-01 5.31515777e-02 1.63033069e-03 2.46349303e-03\n",
      "  1.70349315e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(9, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "for epoch in range(50):\n",
    "    nonlinear_model.train_on_batch(X_train, y_train)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('after {} epochs:'.format(epoch+1), nonlinear_model(X_train).numpy(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert these probabilities into class predictions and also report its accuracy.\n",
    "\n",
    "Accuracy is increasing in as epoch number increase. This shows that we have not reach the minima yet, and didn't jumped over it as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 54 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd6f418f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "After 10 epochs:\n",
      "413/413 - 0s - loss: 1.5044 - accuracy: 0.4402\n",
      "\n",
      "Accuracy: 0.4402301609516144\n",
      "\n",
      "\n",
      "\n",
      "After 20 epochs:\n",
      "413/413 - 0s - loss: 1.3758 - accuracy: 0.5706\n",
      "\n",
      "Accuracy: 0.5705958008766174\n",
      "\n",
      "\n",
      "\n",
      "After 30 epochs:\n",
      "413/413 - 0s - loss: 1.2960 - accuracy: 0.6173\n",
      "\n",
      "Accuracy: 0.6173064112663269\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(9, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for epoch in range(30):\n",
    "    nonlinear_model.train_on_batch(X_train, y_train)\n",
    "    predictions = nonlinear_model.predict(X_train)\n",
    "    result = tf.argmax(predictions, axis=1)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('\\nAfter {} epochs:'.format(epoch+1))\n",
    "        test_loss, test_acc = nonlinear_model.evaluate(X_train, y_train, verbose=2)\n",
    "        print('\\nAccuracy:', test_acc)\n",
    "        print('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using minibatching\n",
    "- better than stochastic approach, which determines the gradient based on 1 data point only.\n",
    "- more efficient than using all the data points to determine the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.9414\n",
      "Epoch 2/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.6632\n",
      "Epoch 3/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5877\n",
      "Epoch 4/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5475\n",
      "Epoch 5/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.5047\n",
      "Epoch 6/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4933\n",
      "Epoch 7/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4749\n",
      "Epoch 8/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4567\n",
      "Epoch 9/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4697\n",
      "Epoch 10/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4219\n",
      "Epoch 11/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4299\n",
      "Epoch 12/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4354\n",
      "Epoch 13/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.4089\n",
      "Epoch 14/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3971\n",
      "Epoch 15/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4212\n",
      "Epoch 16/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3861\n",
      "Epoch 17/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3711\n",
      "Epoch 18/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4121\n",
      "Epoch 19/20\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 0.3858\n",
      "Epoch 20/20\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3890\n",
      "413/413 [==============================] - 0s 853us/step - loss: 0.3512\n",
      "final loss: 0.3511732518672943\n",
      "final predictions:\n",
      "[[1.28830754e-04 9.99847651e-01 2.42823262e-07 2.32115181e-05\n",
      "  1.58341318e-09]\n",
      " [7.78633714e-01 2.19196916e-01 4.63099597e-04 1.28280502e-04\n",
      "  1.57806312e-03]\n",
      " [9.65092599e-01 5.56598557e-03 1.19952470e-04 3.14545359e-05\n",
      "  2.91899815e-02]\n",
      " ...\n",
      " [3.34896624e-01 1.05896097e-05 4.84761995e-06 2.65780557e-07\n",
      "  6.65087759e-01]\n",
      " [9.78887737e-01 1.57441720e-02 9.73122296e-05 2.81735774e-05\n",
      "  5.24258986e-03]\n",
      " [9.38689590e-01 1.17902084e-04 1.84216824e-05 9.28402551e-06\n",
      "  6.11647032e-02]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(9, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, batch_size=500, epochs=20)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "print('final predictions:', nonlinear_model.predict(X_train), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Trying different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 1: 1 hidden layer + relu activation function + large learning rate\n",
    "- loss didn't stablize -> learning rate is too large\n",
    "- Although random seed is fixed, randomness still exists because the order of GPU threads executions is still random. Therefore, the final result will based on the average of differnt random seed:\n",
    "    - random seed (0): loss = 0.2996\n",
    "    - random seed (1): loss = 0.4097\n",
    "    - random seed (2): loss = 1.3094\n",
    "    - final loss: 0.6729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.7940\n",
      "Epoch 2/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.5915\n",
      "Epoch 3/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5341\n",
      "Epoch 4/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.5389\n",
      "Epoch 5/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4449\n",
      "Epoch 6/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4235\n",
      "Epoch 7/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4089\n",
      "Epoch 8/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3846\n",
      "Epoch 9/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4080\n",
      "Epoch 10/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3440\n",
      "Epoch 11/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.5378\n",
      "Epoch 12/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3552\n",
      "Epoch 13/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4095\n",
      "Epoch 14/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3314\n",
      "Epoch 15/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3267\n",
      "Epoch 16/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3037\n",
      "Epoch 17/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3030\n",
      "Epoch 18/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3026\n",
      "Epoch 19/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3090\n",
      "Epoch 20/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2940\n",
      "Epoch 21/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2802\n",
      "Epoch 22/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2718\n",
      "Epoch 23/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2706\n",
      "Epoch 24/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3142\n",
      "Epoch 25/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3880\n",
      "Epoch 26/40\n",
      "67/67 [==============================] - 0s 860us/step - loss: 0.2647\n",
      "Epoch 27/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.2656\n",
      "Epoch 28/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2877\n",
      "Epoch 29/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3022\n",
      "Epoch 30/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.2529\n",
      "Epoch 31/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.2445\n",
      "Epoch 32/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2904\n",
      "Epoch 33/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2687\n",
      "Epoch 34/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2437\n",
      "Epoch 35/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2346\n",
      "Epoch 36/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2688\n",
      "Epoch 37/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.2472\n",
      "Epoch 38/40\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3214\n",
      "Epoch 39/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2300\n",
      "Epoch 40/40\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2431\n",
      "413/413 [==============================] - 1s 2ms/step - loss: 0.2997A: 0s - los\n",
      "final loss: 0.2996937036514282\n",
      "final predictions:\n",
      "[[1.0851545e-07 9.9999988e-01 2.5784840e-13 1.0190724e-10 4.3341205e-14]\n",
      " [2.5521456e-03 9.9741274e-01 1.5631497e-07 3.4667723e-05 2.9995920e-07]\n",
      " [9.9343008e-01 3.5176112e-03 7.1262744e-05 1.1063742e-03 1.8746561e-03]\n",
      " ...\n",
      " [9.4531137e-01 2.3307442e-03 4.9697678e-04 8.3567749e-04 5.1025249e-02]\n",
      " [9.8315823e-01 1.0376637e-02 1.8441056e-04 1.4296847e-03 4.8509920e-03]\n",
      " [9.7960335e-01 1.3877295e-03 5.4760596e-05 1.1696396e-04 1.8837081e-02]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "tf.random.set_seed(0)\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(20, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.75),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, batch_size=200, epochs=40)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "print('final predictions:', nonlinear_model.predict(X_train), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 2: 1 hidden layer + sigmoid activation + medium learning rate\n",
    "- with reduced learning rate, didn't jump over the minima anymore. \n",
    "- However, when using sigmoid or tanh as activation function, the loss of the last epoch always jumped back up to very high value 0.5/0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 1.2060 - accuracy: 0.5028\n",
      "Epoch 2/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.9820 - accuracy: 0.6393\n",
      "Epoch 3/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.8114 - accuracy: 0.6968\n",
      "Epoch 4/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.7129 - accuracy: 0.7537\n",
      "Epoch 5/60\n",
      "67/67 [==============================] - ETA: 0s - loss: 0.6592 - accuracy: 0.77 - 0s 1ms/step - loss: 0.6625 - accuracy: 0.7697\n",
      "Epoch 6/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.6310 - accuracy: 0.7789\n",
      "Epoch 7/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.7845\n",
      "Epoch 8/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7873\n",
      "Epoch 9/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7858\n",
      "Epoch 10/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7930\n",
      "Epoch 11/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7952\n",
      "Epoch 12/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 0.7998\n",
      "Epoch 13/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.7988\n",
      "Epoch 14/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4799 - accuracy: 0.8013\n",
      "Epoch 15/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.8050\n",
      "Epoch 16/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.8068\n",
      "Epoch 17/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.8159\n",
      "Epoch 18/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8309\n",
      "Epoch 19/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.4038 - accuracy: 0.8406\n",
      "Epoch 20/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3899 - accuracy: 0.8436\n",
      "Epoch 21/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3840 - accuracy: 0.8440\n",
      "Epoch 22/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3710 - accuracy: 0.8481\n",
      "Epoch 23/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3662 - accuracy: 0.8457\n",
      "Epoch 24/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8470\n",
      "Epoch 25/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8468\n",
      "Epoch 26/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8494\n",
      "Epoch 27/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8536\n",
      "Epoch 28/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8537\n",
      "Epoch 29/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3453 - accuracy: 0.8549\n",
      "Epoch 30/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8583\n",
      "Epoch 31/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8579\n",
      "Epoch 32/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8606\n",
      "Epoch 33/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8595\n",
      "Epoch 34/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8618\n",
      "Epoch 35/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3162 - accuracy: 0.8634\n",
      "Epoch 36/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3140 - accuracy: 0.8685\n",
      "Epoch 37/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3169 - accuracy: 0.8669\n",
      "Epoch 38/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8624\n",
      "Epoch 39/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3064 - accuracy: 0.8695\n",
      "Epoch 40/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3155 - accuracy: 0.8637\n",
      "Epoch 41/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3135 - accuracy: 0.8686\n",
      "Epoch 42/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3187 - accuracy: 0.8670\n",
      "Epoch 43/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.8722\n",
      "Epoch 44/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3156 - accuracy: 0.8671\n",
      "Epoch 45/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8690\n",
      "Epoch 46/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3051 - accuracy: 0.8697\n",
      "Epoch 47/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8682\n",
      "Epoch 48/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.8713\n",
      "Epoch 49/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8710\n",
      "Epoch 50/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8701\n",
      "Epoch 51/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.8709\n",
      "Epoch 52/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8733\n",
      "Epoch 53/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.3046 - accuracy: 0.8712\n",
      "Epoch 54/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2962 - accuracy: 0.8755\n",
      "Epoch 55/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2945 - accuracy: 0.8764\n",
      "Epoch 56/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8761\n",
      "Epoch 57/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.8746\n",
      "Epoch 58/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8777\n",
      "Epoch 59/60\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8743\n",
      "Epoch 60/60\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 0.2907 - accuracy: 0.8780\n",
      "413/413 [==============================] - 0s 965us/step - loss: 0.4756 - accuracy: 0.8111\n",
      "final loss: [0.47559696435928345, 0.8111136555671692]\n",
      "final predictions:\n",
      "[[1.76642006e-05 9.99901891e-01 4.59843328e-08 8.04046140e-05\n",
      "  2.09448171e-12]\n",
      " [3.13976267e-03 9.96857285e-01 3.75936793e-07 2.64263167e-06\n",
      "  2.30270733e-10]\n",
      " [9.84216392e-01 1.44387111e-02 8.50214856e-05 8.10880010e-05\n",
      "  1.17879105e-03]\n",
      " ...\n",
      " [6.50275350e-01 1.05579384e-04 8.22131551e-05 1.76041685e-05\n",
      "  3.49519253e-01]\n",
      " [9.91004586e-01 6.63143490e-03 7.84797303e-05 5.33300154e-05\n",
      "  2.23236019e-03]\n",
      " [8.83802533e-01 6.13371376e-05 5.12674269e-05 3.75201089e-05\n",
      "  1.16047360e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=(9,), activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(20, input_shape=(9,), activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.5),\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, batch_size=200, epochs=60)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "print('final predictions:', nonlinear_model.predict(X_train), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model 3: 3 hidden layers and more nodes + relu activation + low learning rate\n",
    "- final loss = 0.17 with random seed 2 (the best performance)\n",
    "- with reduced learning rate, didn't jump over the minima anymore\n",
    "- Since we observed the loss is decreasing (and a slower learning rate has been adopted), the number of epochs has been increased. With 100 epochs, we can observed that the loss has stablised at around 0.17 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1.2113\n",
      "Epoch 2/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.8668\n",
      "Epoch 3/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.7127\n",
      "Epoch 4/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6312\n",
      "Epoch 5/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5997\n",
      "Epoch 6/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5665\n",
      "Epoch 7/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5102\n",
      "Epoch 8/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.5069\n",
      "Epoch 9/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4838\n",
      "Epoch 10/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4775\n",
      "Epoch 11/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.4420\n",
      "Epoch 12/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3938\n",
      "Epoch 13/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3988\n",
      "Epoch 14/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3954\n",
      "Epoch 15/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3614\n",
      "Epoch 16/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3710\n",
      "Epoch 17/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3481\n",
      "Epoch 18/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3405\n",
      "Epoch 19/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3294\n",
      "Epoch 20/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3205\n",
      "Epoch 21/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3165\n",
      "Epoch 22/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3306\n",
      "Epoch 23/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3251\n",
      "Epoch 24/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3118\n",
      "Epoch 25/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2854\n",
      "Epoch 26/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2912\n",
      "Epoch 27/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.3043\n",
      "Epoch 28/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2874\n",
      "Epoch 29/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2809\n",
      "Epoch 30/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2678\n",
      "Epoch 31/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2908\n",
      "Epoch 32/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2956\n",
      "Epoch 33/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 34/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2676\n",
      "Epoch 35/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3017\n",
      "Epoch 36/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2631\n",
      "Epoch 37/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2594\n",
      "Epoch 38/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2579\n",
      "Epoch 39/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2639\n",
      "Epoch 40/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2438\n",
      "Epoch 41/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2575\n",
      "Epoch 42/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2428\n",
      "Epoch 43/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 44/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2353\n",
      "Epoch 45/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2470\n",
      "Epoch 46/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2466\n",
      "Epoch 47/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2319\n",
      "Epoch 48/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2336\n",
      "Epoch 49/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2385\n",
      "Epoch 50/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2518\n",
      "Epoch 51/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2288\n",
      "Epoch 52/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2533\n",
      "Epoch 53/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2266\n",
      "Epoch 54/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2207\n",
      "Epoch 55/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2448\n",
      "Epoch 56/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2281\n",
      "Epoch 57/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2336\n",
      "Epoch 58/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2085\n",
      "Epoch 59/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2335\n",
      "Epoch 60/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2194\n",
      "Epoch 61/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2307\n",
      "Epoch 62/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2413\n",
      "Epoch 63/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2006\n",
      "Epoch 64/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2284\n",
      "Epoch 65/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2317\n",
      "Epoch 66/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1975\n",
      "Epoch 67/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2232\n",
      "Epoch 68/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1839\n",
      "Epoch 69/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2214\n",
      "Epoch 70/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1941\n",
      "Epoch 71/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2145\n",
      "Epoch 72/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1873\n",
      "Epoch 73/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2260\n",
      "Epoch 74/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1882\n",
      "Epoch 75/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2060\n",
      "Epoch 76/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2029\n",
      "Epoch 77/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2049\n",
      "Epoch 78/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1844\n",
      "Epoch 79/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1986\n",
      "Epoch 80/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2045\n",
      "Epoch 81/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2117\n",
      "Epoch 82/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1959\n",
      "Epoch 83/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1849\n",
      "Epoch 84/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2056\n",
      "Epoch 85/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1783\n",
      "Epoch 86/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2028\n",
      "Epoch 87/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1855\n",
      "Epoch 88/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1848\n",
      "Epoch 89/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2019\n",
      "Epoch 90/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1902\n",
      "Epoch 91/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1717\n",
      "Epoch 92/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.2083\n",
      "Epoch 93/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1815\n",
      "Epoch 94/95\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1864\n",
      "Epoch 95/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1934\n",
      "413/413 [==============================] - 0s 1ms/step - loss: 0.1786\n",
      "final loss: 0.1786077618598938\n",
      "final predictions:\n",
      "[[1.0303806e-11 1.0000000e+00 5.3018200e-20 6.1619292e-15 2.5757645e-18]\n",
      " [4.3722141e-01 5.6269628e-01 2.3432017e-06 2.6243855e-05 5.3715175e-05]\n",
      " [9.9624759e-01 1.4754900e-03 6.0978306e-05 4.3662143e-04 1.7793634e-03]\n",
      " ...\n",
      " [7.1759814e-01 2.2578666e-03 5.7801820e-04 3.0658260e-04 2.7925941e-01]\n",
      " [9.9712092e-01 2.3204624e-03 2.2266644e-05 1.1826566e-04 4.1804725e-04]\n",
      " [9.8772240e-01 1.2767711e-04 3.6085181e-05 3.3446398e-05 1.2080414e-02]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "\n",
    "tf.random.set_seed(2)\n",
    "\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(18, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.25),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, batch_size=500, epochs=95)\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "y_train_pred = nonlinear_model.predict(X_train)\n",
    "print('final predictions:', y_train_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the development dataset. If performance on X_dev is too poor, adjust hyper parameters (width depth, learning rate etc) above, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 1ms/step - loss: 0.1972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19715756177902222"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlinear_model.evaluate(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acheived 0.8056 accuracy in development dataset. Satisfied with the performance. Hence, can evaluate on test set, to check the realistic performance. \n",
    "\n",
    "Performance on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 1s 4ms/step - loss: 0.2130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2130109816789627"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlinear_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Achieve 80.91% on test set. Accuracy performance on test set similar to dev set, which is good to have. However ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5706  104    0   12   26]\n",
      " [  85 4127    0    4    1]\n",
      " [   0    0    0    0    2]\n",
      " [  70   56    0 1365    0]\n",
      " [ 518    0    0  211  922]]\n",
      "\n",
      "\n",
      "[[1744   38    0    5    8]\n",
      " [  42 1281    0    1    0]\n",
      " [   0    0    0    0    1]\n",
      " [  21   21    0  394    0]\n",
      " [ 176    0    0   93  303]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = nonlinear_model.predict(X_train)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "conf_mx = tf.math.confusion_matrix(y_train, y_pred).numpy()\n",
    "print(conf_mx)\n",
    "print(\"\\n\")\n",
    "\n",
    "y_pred = nonlinear_model.predict(X_test)\n",
    "y_pred = tf.argmax(y_pred, axis=1)\n",
    "conf_mx = tf.math.confusion_matrix(y_test, y_pred).numpy()\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy may not be the right evaluation metric to use with this dataset because of imbalanced data. As shown in the confusion matrix, there is no data about the third classes (\"ISLAND\"). For severely imbalanced classes, we can get high overall accuracy without much effort, but this does not mean we obtained good insights of the distributions. The overall accuracy might be high, but for the minority class like 'ISLAND', we will have very low recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "### Visualise trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clear any logs from previous runs by running `rm -rf ./logs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/95\n",
      " 2/27 [=>............................] - ETA: 0s - loss: 1.6561WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0623s). Check your callbacks.\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 1.2113 - val_loss: 0.9691\n",
      "Epoch 2/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.8668 - val_loss: 0.7620\n",
      "Epoch 3/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.7127 - val_loss: 0.6574\n",
      "Epoch 4/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.6312 - val_loss: 0.8348\n",
      "Epoch 5/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.5997 - val_loss: 0.6910\n",
      "Epoch 6/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.5665 - val_loss: 0.5011\n",
      "Epoch 7/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.5102 - val_loss: 0.8057\n",
      "Epoch 8/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.5069 - val_loss: 0.4313\n",
      "Epoch 9/95\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.4838 - val_loss: 0.4213\n",
      "Epoch 10/95\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 0.4775 - val_loss: 0.5947\n",
      "Epoch 11/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4420 - val_loss: 0.4038\n",
      "Epoch 12/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3938 - val_loss: 0.6057\n",
      "Epoch 13/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3988 - val_loss: 0.3329\n",
      "Epoch 14/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3954 - val_loss: 0.4135\n",
      "Epoch 15/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3614 - val_loss: 0.6556\n",
      "Epoch 16/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3710 - val_loss: 0.4014\n",
      "Epoch 17/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3481 - val_loss: 0.3140\n",
      "Epoch 18/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3405 - val_loss: 0.3856\n",
      "Epoch 19/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3294 - val_loss: 0.3899\n",
      "Epoch 20/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3205 - val_loss: 0.4243\n",
      "Epoch 21/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3165 - val_loss: 0.3169\n",
      "Epoch 22/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3306 - val_loss: 0.3076\n",
      "Epoch 23/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.3251 - val_loss: 0.2605\n",
      "Epoch 24/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3118 - val_loss: 0.2776\n",
      "Epoch 25/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2854 - val_loss: 0.2839\n",
      "Epoch 26/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2912 - val_loss: 0.5306\n",
      "Epoch 27/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3043 - val_loss: 0.3010\n",
      "Epoch 28/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2874 - val_loss: 0.2475\n",
      "Epoch 29/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2809 - val_loss: 0.3394\n",
      "Epoch 30/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2678 - val_loss: 0.4232\n",
      "Epoch 31/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2908 - val_loss: 0.2912\n",
      "Epoch 32/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2956 - val_loss: 0.3943\n",
      "Epoch 33/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2799 - val_loss: 0.2511\n",
      "Epoch 34/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2676 - val_loss: 0.3451\n",
      "Epoch 35/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3017 - val_loss: 0.2704\n",
      "Epoch 36/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2631 - val_loss: 0.2313\n",
      "Epoch 37/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2594 - val_loss: 0.2281\n",
      "Epoch 38/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2579 - val_loss: 0.2222\n",
      "Epoch 39/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2639 - val_loss: 0.4264\n",
      "Epoch 40/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2438 - val_loss: 0.2059\n",
      "Epoch 41/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2575 - val_loss: 0.2698\n",
      "Epoch 42/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2428 - val_loss: 0.3015\n",
      "Epoch 43/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2672 - val_loss: 0.2763\n",
      "Epoch 44/95\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2353 - val_loss: 0.2199\n",
      "Epoch 45/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2470 - val_loss: 0.2643\n",
      "Epoch 46/95\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2466 - val_loss: 0.2223\n",
      "Epoch 47/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2319 - val_loss: 0.2544\n",
      "Epoch 48/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2336 - val_loss: 0.2923\n",
      "Epoch 49/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2385 - val_loss: 0.3761\n",
      "Epoch 50/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2518 - val_loss: 0.2832\n",
      "Epoch 51/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2288 - val_loss: 0.2687\n",
      "Epoch 52/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2533 - val_loss: 0.2597\n",
      "Epoch 53/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2266 - val_loss: 0.2792\n",
      "Epoch 54/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2207 - val_loss: 0.2218\n",
      "Epoch 55/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2448 - val_loss: 0.1958\n",
      "Epoch 56/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2281 - val_loss: 0.2203\n",
      "Epoch 57/95\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.2336 - val_loss: 0.2475\n",
      "Epoch 58/95\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2085 - val_loss: 0.2962\n",
      "Epoch 59/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2335 - val_loss: 0.1792\n",
      "Epoch 60/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2194 - val_loss: 0.2190\n",
      "Epoch 61/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2307 - val_loss: 0.4055\n",
      "Epoch 62/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2413 - val_loss: 0.1811\n",
      "Epoch 63/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2006 - val_loss: 0.2180\n",
      "Epoch 64/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2284 - val_loss: 0.1987\n",
      "Epoch 65/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2317 - val_loss: 0.2375\n",
      "Epoch 66/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1975 - val_loss: 0.1661\n",
      "Epoch 67/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2232 - val_loss: 0.2244\n",
      "Epoch 68/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1839 - val_loss: 0.1848\n",
      "Epoch 69/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2214 - val_loss: 0.2465\n",
      "Epoch 70/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1941 - val_loss: 0.1705\n",
      "Epoch 71/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2145 - val_loss: 0.1729\n",
      "Epoch 72/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1873 - val_loss: 0.2969\n",
      "Epoch 73/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2260 - val_loss: 0.1996\n",
      "Epoch 74/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1882 - val_loss: 0.1728\n",
      "Epoch 75/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2060 - val_loss: 0.1693\n",
      "Epoch 76/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2029 - val_loss: 0.2028\n",
      "Epoch 77/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2049 - val_loss: 0.3378\n",
      "Epoch 78/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1844 - val_loss: 0.3563\n",
      "Epoch 79/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1986 - val_loss: 0.1888\n",
      "Epoch 80/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2045 - val_loss: 0.1719\n",
      "Epoch 81/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2117 - val_loss: 0.1699\n",
      "Epoch 82/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1959 - val_loss: 0.2156\n",
      "Epoch 83/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1849 - val_loss: 0.2328\n",
      "Epoch 84/95\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2056 - val_loss: 0.2355\n",
      "Epoch 85/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1783 - val_loss: 0.2487\n",
      "Epoch 86/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.2028 - val_loss: 0.3178\n",
      "Epoch 87/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1855 - val_loss: 0.1447\n",
      "Epoch 88/95\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1848 - val_loss: 0.1717\n",
      "Epoch 89/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2019 - val_loss: 0.1551\n",
      "Epoch 90/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1902 - val_loss: 0.1512\n",
      "Epoch 91/95\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.1717 - val_loss: 0.1690\n",
      "Epoch 92/95\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.2083 - val_loss: 0.1686\n",
      "Epoch 93/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1815 - val_loss: 0.1876\n",
      "Epoch 94/95\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1864 - val_loss: 0.2291\n",
      "Epoch 95/95\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1934 - val_loss: 0.1786\n",
      "413/413 [==============================] - 0s 957us/step - loss: 0.1786\n",
      "final loss: 0.1786077618598938\n",
      "final predictions:\n",
      "[[1.0303806e-11 1.0000000e+00 5.3018200e-20 6.1619292e-15 2.5757645e-18]\n",
      " [4.3722141e-01 5.6269628e-01 2.3432017e-06 2.6243855e-05 5.3715175e-05]\n",
      " [9.9624759e-01 1.4754900e-03 6.0978306e-05 4.3662143e-04 1.7793634e-03]\n",
      " ...\n",
      " [7.1759814e-01 2.2578666e-03 5.7801820e-04 3.0658260e-04 2.7925941e-01]\n",
      " [9.9712092e-01 2.3204624e-03 2.2266644e-05 1.1826566e-04 4.1804725e-04]\n",
      " [9.8772240e-01 1.2767711e-04 3.6085181e-05 3.3446398e-05 1.2080414e-02]]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session\n",
    "tf.random.set_seed(2)\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(18, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.25),\n",
    "                        loss='sparse_categorical_crossentropy')\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "nonlinear_model.fit(X_train, y_train, \n",
    "                    batch_size=500, \n",
    "                    epochs=95,\n",
    "                    validation_data = (X_train, y_train),\n",
    "                    callbacks=[tensorboard_callback])\n",
    "\n",
    "print('final loss:', nonlinear_model.evaluate(X_train, y_train))\n",
    "print('final predictions:', nonlinear_model.predict(X_train), sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 815), started 0:14:27 ago. (Use '!kill 815' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-af57295590621996\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-af57295590621996\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keeping track of the history\n",
    "\n",
    "understand more about the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Dense at 0x7fccb5a46e50>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcc97d80610>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcc9b075460>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcc97ec1f10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcc97f7fd00>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(2)\n",
    "nonlinear_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(18, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(36, input_shape=(9,), activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "nonlinear_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 36)                684       \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 36)                1332      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 5)                 185       \n",
      "=================================================================\n",
      "Total params: 3,713\n",
      "Trainable params: 3,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nonlinear_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
